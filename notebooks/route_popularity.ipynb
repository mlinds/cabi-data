{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cabi\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating trip summary table\n",
    "Our goal is to create a table showing the stations in a certain pair of stations\n",
    "## Loading trip data\n",
    "First we load the table of all trips, and remove any with incomplete data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cabi.return_trip_datatable()\n",
    "df.to_parquet(\"../data/interim/comb_trips.gzip\", compression=\"gzip\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31135156 total trips\n",
      "30701825 after removing trips with NA values \n",
      " 433331 trips removed due to NA values\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet(\"../data/interim/comb_trips.gzip\")\n",
    "total = len(df)\n",
    "print(f\"{total} total trips\")\n",
    "# clean the NA values out\n",
    "df = df.dropna()\n",
    "total_nonna = len(df)\n",
    "print(\n",
    "    f\"{total_nonna} after removing trips with NA values \\n {total-total_nonna} trips removed due to NA values\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing invalid trips\n",
    "We have some number of trips where the end station is listed as 0. Obviously these are invalid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30700262 trips after removing trips with missing origin or destination \n",
      " 1563 trips removed\n"
     ]
    }
   ],
   "source": [
    "df = df[df.start_station_id > 0]\n",
    "df = df[df.end_station_id > 0]\n",
    "total_mappable = len(df)\n",
    "print(\n",
    "    f\"{total_mappable} trips after removing trips with missing origin or destination \\n {total_nonna-total_mappable} trips removed\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing trips from removed stations\n",
    "We also need to make sure we know the location of the station. Therefore we load the list of stations names. Maybe in the future if I can find a table of the locations of removed stations and we can add them to the visualization\n",
    "### loading our current stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define which attributes to lookup from airports.csv\n",
    "cabi_stations = \"https://raw.githubusercontent.com/mlinds/cabi-data/main/data/processed/stationLookup.csv\"\n",
    "station_names_list = list(pd.read_csv(cabi_stations).short_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting only trips involving extant stations\n",
    "We rewrite the dataframe to include only stations that exist in our location lookup table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30377585 trips after removing trips from stations that dont exist \n",
      " 322677 trips were removed\n"
     ]
    }
   ],
   "source": [
    "df = df[df.end_station_id.map(lambda x: x in station_names_list)]\n",
    "df = df[df.start_station_id.map(lambda x: x in station_names_list)]\n",
    "total_current = len(df)\n",
    "print(\n",
    "    f\"{total_current} trips after removing trips from stations that dont exist \\n {total_mappable-total_current} trips were removed\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing self-trips\n",
    "There are interesting but they aren't easy to show on a map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29016683 trips after removing trips from stations that dont exist \n",
      " 1360902 trips were removed\n"
     ]
    }
   ],
   "source": [
    "df = df[df.start_station_id != df.end_station_id]\n",
    "total_nonself = len(df)\n",
    "print(\n",
    "    f\"{total_nonself} trips after removing trips from stations that dont exist \\n {total_current-total_nonself} trips were removed\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging based on which stations are involved\n",
    "Now to merge based on the same *pairing* of stations (e.g. we do not need to care about which is the origin and which is the destination) to calculate the popularity of that route."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of the sorted stations\n",
    "sorted_stations = [\n",
    "    sorted([int(x), int(y)]) for x, y in zip(df.start_station_id, df.end_station_id)\n",
    "]\n",
    "sorted_stations_combined = [int(str(x) + str(y)) for x, y in sorted_stations]\n",
    "\n",
    "# we also want to create an integer value for the station pair that is not sorted\n",
    "unsorted_stations_combined = [\n",
    "    int(str(x) + str(y)) for x, y in zip(df.start_station_id, df.end_station_id)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.assign(\n",
    "    sorted_stations=sorted_stations_combined, unsrt=unsorted_stations_combined\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (\n",
    "    df.groupby(\"sorted_stations\")\n",
    "    .count()\n",
    "    .reset_index()[[\"sorted_stations\", \"end_station_id\"]]\n",
    ")\n",
    "a.columns = [\"sorted\", \"popularity\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.unsrt.value_counts().sum() == df.sorted_stations.value_counts().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>st</th>\n",
       "      <th>en</th>\n",
       "      <th>popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31000</td>\n",
       "      <td>31002</td>\n",
       "      <td>987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>31000</td>\n",
       "      <td>31233</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>31000</td>\n",
       "      <td>31907</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>31000</td>\n",
       "      <td>31232</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>31000</td>\n",
       "      <td>31231</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32803</th>\n",
       "      <td>32609</td>\n",
       "      <td>31079</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19030</th>\n",
       "      <td>32609</td>\n",
       "      <td>31038</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146542</th>\n",
       "      <td>32609</td>\n",
       "      <td>32600</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107630</th>\n",
       "      <td>32609</td>\n",
       "      <td>31312</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146819</th>\n",
       "      <td>32609</td>\n",
       "      <td>32232</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>146820 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           st     en  popularity\n",
       "0       31000  31002         987\n",
       "271     31000  31233          41\n",
       "486     31000  31907           7\n",
       "269     31000  31232          34\n",
       "267     31000  31231          81\n",
       "...       ...    ...         ...\n",
       "32803   32609  31079           5\n",
       "19030   32609  31038          16\n",
       "146542  32609  32600          67\n",
       "107630  32609  31312           6\n",
       "146819  32609  32232           5\n",
       "\n",
       "[146820 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "undirected_pop = (\n",
    "    df.groupby([\"start_station_id\", \"end_station_id\", \"sorted_stations\"])\n",
    "    .size()\n",
    "    .reset_index()\n",
    "    .drop(columns=0)\n",
    "    .merge(a, left_on=\"sorted_stations\", right_on=\"sorted\")\n",
    "    .drop(columns=[\"sorted_stations\", \"sorted\"])\n",
    "    .sort_values(\"start_station_id\", ascending=True)\n",
    ")\n",
    "\n",
    "# columns names are changed for easier access in altair\n",
    "undirected_pop.columns = [\"st\", \"en\", \"popularity\"]\n",
    "undirected_pop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "undirected_pop.to_csv(\n",
    "    \"../data/processed/connections_csv.csv\",\n",
    "    columns=[\"st\", \"en\", \"popularity\"],\n",
    "    index=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28900960.5"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "undirected_pop.popularity.sum() / 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now reassign the start and end, so that we can seperately plot them later"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "be2a6025bae76a7516ab88c2f31b9863ea4cd93e966fcc072327ea369c90eae2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
